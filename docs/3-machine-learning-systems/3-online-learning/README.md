# Online Learning

These online learning systems allows us to model problems where we have a continuous stream of data coming in and we would like an algorithm to learn from that. Today, many of the largest websites use different versions of online learning algorithms to learn from the flood of users that keep on coming to back to the website. Specifically, if you have a continuous stream of data generated by a continuous stream of users coming to your website, what you can do is sometimes use an online learning algorithm to learn user preferences from the stream of data and use that to optimize some of the decisions on your website.

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
<!-- END doctoc generated TOC please keep comment here to allow auto update -->

- [Shipping Service Example](#shipping-service-example)
- [Product Search Example](#product-search-example)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## Shipping Service Example

Let's say users come and tell you the origin and destination of an order.

- You offer to ship the package for some amount of money (e.g. $10 - $50).
- Based on the price you offer, sometimes the user uses your service (y = 1), sometimes they don't (y = 0).
- Build an algorithm to optimize what price we offer to the users.

We could capture features such as:

- Information about user.
- Origin and destination.

We determine the probability of a user selecting our service, so we want to optimize the price to improve this probability.

To model this probability we have something like:

- p(y = 1|x; θ), which is read as the probability that y = 1, given x, parameterized by θ.

This model can be built with models such as:

- Logistic regression.
- Neural network.

If you have a website that continuously runs an online learning algorithm, the workflow would be something like this:

- The user is represented as an (x,y) pair where:
  - x is the feature vector including price we offer, origin, destination, etc.
  - y indicates if they chose to use our service or not.
- The algorithm updates θ using just the (x,y) pair (stochastic gradient descent).
  ![Shipping Service Example I](https://www.holehouse.org/mlclass/17_Large_Scale_Machine_Learning_files/Image%20[25].png)
- We basically update all the θ parameters every time we get some new data.

While in previous examples we might have described the data example as (x<sup>i</sup>, y<sup>i</sup>), for an online learning problem we discard this idea of a data set, and instead we have a continuous stream of data so indexing is largely irrelevant as you're not storing the data (although presumably you could store it).

If you have a major website where you have a massive stream of data then this kind of algorithm is pretty reasonable because you would be free of the need to deal with all your training data.

An online algorithm can also adapt to changing user preferences:

- Over time users may become more price sensitive.
- The algorithm adapts and learns to predict new optimal prices.
- Your system is dynamic.

## Product Search Example

Let's say you run an online store that sells cellphones. In the website, there is a UI where the user can type in a query like "Android phone 1080p camera", and we want to offer the user 10 phones per query.

How do we do this:

- For each phone and given a specific user query, we create a feature vector (x) which has data like features of the phone, how many words in the user query match the name of the phone, how many words in user query match description of phone, etc. Essentially, we compare metadata.
- We want to estimate the probability of a user selecting a phone, so define:
  - y = 1 if a user clicks on a link.
  - y = 0 otherwise.

So we want to learn p(y = 1|x ; θ). This is called the predicted click through rate (CTR). If you can estimate the CTR for any phone we can use this to show the highest probability phones first. If we display 10 phones per search, it means for each search we generate 10 training examples of data. In other words, the user can click through one or more, or none of them, which defines how well the prediction performed.

Other things you can do:

- Special offers to show the user.
- Show news articles by learning what users like.
- Product recommendations.

These problems could have been formulated using standard techniques, but they are the kinds of problems where you have so much data that this is a better way to do things.
